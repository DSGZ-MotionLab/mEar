{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal TCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Example Testing please run the Section \"Model Definition\" and \"Testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import utilities, configuration\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pickle import dump\n",
    "\n",
    "# Group the dataframe by 'walk_id'\n",
    "groups = configuration.df.groupby(\"walk_id\")\n",
    "\n",
    "# ===========================================================================\n",
    "# Iterate through groups to create sequences and labels\n",
    "\n",
    "# Initialize empty lists to store sequences, labels, and IDs\n",
    "data_sequences = []\n",
    "data_labels = []\n",
    "data_ids = []\n",
    "\n",
    "# Iterate through groups to create sequences and labels\n",
    "dataset_number = 0\n",
    "for name, group in groups:\n",
    "\n",
    "        data_temp = group[[\"acc_x\", \"acc_y\", \"acc_z\"]].to_numpy()  # Input data\n",
    "        event_data = group[\"events\"].to_numpy()  # Target labels\n",
    "\n",
    "        event_data[event_data == 2] = 1  # 1,2 IC\n",
    "        event_data[event_data == 3] = 2  # FC\n",
    "        event_data[event_data == 4] = 2  # FC\n",
    "\n",
    "        data_labels_temp = np.empty([2, len(event_data)])\n",
    "        data_labels_temp[0] = np.where(event_data == 1, 1, 0)\n",
    "        data_labels_temp[1] = np.where(event_data == 2, 1, 0)\n",
    "        data_labels_temp = data_labels_temp.transpose(1, 0)\n",
    "        \n",
    "        # take data in account if longer than window_size\n",
    "        if len(data_labels_temp) > configuration.window_size:\n",
    "\n",
    "            # Apply sliding window\n",
    "            seq, lbl = utilities.sliding_window(data_temp, data_labels_temp, configuration.window_size, configuration.stride)\n",
    "\n",
    "            for s in seq:\n",
    "                data_sequences.extend(torch.tensor(s, dtype=torch.float32))\n",
    "\n",
    "            for l in lbl:\n",
    "                data_labels.extend(torch.tensor(l, dtype=torch.float32))\n",
    "                data_ids.extend([group[\"id\"][group.first_valid_index()]] * len(l))\n",
    "\n",
    "            dataset_number += 1\n",
    "            \n",
    "# ===========================================================================\n",
    "# Stack data and labels\n",
    "data_sequences = torch.vstack(data_sequences) # shape(samples,3)\n",
    "data_labels = torch.vstack(data_labels)  # shape(samples,1)\n",
    "\n",
    "# Split Datasets\n",
    "train_index, test_index = next(configuration.group_split.split(data_sequences, data_labels, data_ids))\n",
    "\n",
    "# ===========================================================================\n",
    "# Prepare training datasets\n",
    "X = data_sequences[train_index]\n",
    "y = data_labels[train_index]\n",
    "ids = [data_ids[i] for i in train_index]\n",
    "\n",
    "# ===========================================================================\n",
    "# Setup scaler only with training data; no scaling for class labels\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "x_np = X.numpy()\n",
    "\n",
    "# Reshape the array to 2D (necessary for the scaler)\n",
    "n_samples, n_features = x_np.shape\n",
    "x_np_reshaped = x_np.reshape(-1, n_features)\n",
    "\n",
    "# Apply the RobustScaler\n",
    "scaler_data = RobustScaler().fit(x_np_reshaped)\n",
    "\n",
    "# Save scaler parameters\n",
    "dump(scaler_data, open('checkpoints/scaler_temporal_input.pkl', 'wb'))\n",
    "\n",
    "x_scaled_np_reshaped = scaler_data.transform(x_np_reshaped)\n",
    "\n",
    "# Reshape the array back to its original shape\n",
    "x_scaled_np = x_scaled_np_reshaped.reshape(n_samples,n_features)\n",
    "\n",
    "# Convert the scaled array back to a PyTorch tensor\n",
    "X = torch.from_numpy(x_scaled_np)\n",
    "\n",
    "# Create Fullwalk Datasets for unseen Testing\n",
    "# ===========================================================================\n",
    "# Initialize empty lists to store sequences and labels\n",
    "data_sequences = []\n",
    "data_labels = []\n",
    "test_ids_fullwalk = []\n",
    "walk_ids_fullwalk = []\n",
    "walk_speed = []\n",
    "\n",
    "ids_test = [data_ids[i] for i in test_index]\n",
    "\n",
    "# Filter by test_ids\n",
    "df_test = configuration.df[configuration.df[\"id\"].isin(ids_test)]\n",
    "\n",
    "# Group by \"walk_id\"\n",
    "df_test_groups = df_test.groupby(\"walk_id\")\n",
    "\n",
    "dataset_number = 0\n",
    "for name, group in df_test_groups:\n",
    "\n",
    "        data_temp = group[[\"acc_x\", \"acc_y\", \"acc_z\"]].to_numpy()  # Input data\n",
    "        event_data = group[\"events\"].to_numpy()  # Target labels\n",
    "\n",
    "        event_data[event_data == 2] = 1  # Right steps as class 2\n",
    "        event_data[event_data == 3] = 2  # FC\n",
    "        event_data[event_data == 4] = 2  # FC\n",
    "\n",
    "        data_labels_temp = np.empty([2, len(event_data)])\n",
    "        data_labels_temp[0] = np.where(event_data == 1, 1, 0)\n",
    "        data_labels_temp[1] = np.where(event_data == 2, 1, 0)\n",
    "        data_labels_temp = data_labels_temp.transpose(1, 0)\n",
    "\n",
    "        data_sequences.append(scaler_data.transform(torch.tensor(data_temp, dtype=torch.float32)))\n",
    "        data_labels.append(torch.tensor(data_labels_temp, dtype=torch.float32))\n",
    "        test_ids_fullwalk.extend([group[\"id\"][group.first_valid_index()]])\n",
    "        walk_ids_fullwalk.append(group[\"walk_id\"][group.first_valid_index()])\n",
    "        walk_speed.extend([group[\"speed\"][group.first_valid_index()]])\n",
    "\n",
    "# Prepare Test Dataloader\n",
    "test_dataset_fullwalk = utilities.CustomDataset(data_sequences, data_labels)\n",
    "\n",
    "# Get the first three examples from the test dataset\n",
    "testing_fullwalk_examples = [test_dataset_fullwalk[i] for i in range(3)]\n",
    "\n",
    "# Dump the testing_fullwalk_examples into a pickle file\n",
    "with open('example_data/testing_fullwalk_examples_temporal.pkl', 'wb') as f:\n",
    "    dump(testing_fullwalk_examples, f)\n",
    "\n",
    "test_loader_fullwalk = DataLoader(test_dataset_fullwalk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import configuration\n",
    "from torchsummary import summary\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('svg')\n",
    "graphviz.set_default_format('svg')\n",
    "\n",
    "# Define a block of the Temporal Convolutional Network (TCN)\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.2):\n",
    "        super(TCNBlock, self).__init__()\n",
    "        # Calculate padding to ensure the output has the same length as the input\n",
    "        padding = (kernel_size - 1) * dilation // 2\n",
    "        # Define the first convolutional layer with the given parameters\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=padding, dilation=dilation)\n",
    "        # Define batch normalization to normalize the output of the convolutional layer\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Define ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        # Define dropout for regularization to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layer\n",
    "        out = self.conv1(x)\n",
    "        # Apply batch normalization\n",
    "        out = self.bn1(out)\n",
    "        # Apply ReLU activation\n",
    "        out = self.relu(out)\n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "# Define the overall TCN structure\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_dim, kernel_size=3, dilation_list=[1], dropout=0.2, out_channels=16):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        channels = input_dim\n",
    "        # Create TCN blocks based on the dilation list\n",
    "        for i, dilation in enumerate(dilation_list):\n",
    "            layers.append(TCNBlock(channels, out_channels, kernel_size, dilation, dropout))\n",
    "            # Update the number of input channels for the next layer\n",
    "            channels = out_channels\n",
    "        # Combine all TCN blocks into a sequential network\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Permute input to (batch_size, channels, seq_len) for Conv1d\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Pass input through the TCN network\n",
    "        x = self.network(x)\n",
    "        # Permute back to (batch_size, seq_len, channels) for further processing\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "# Define the complete model structure\n",
    "class TemporalTCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, kernel_size=5, dilation_list=[1, 2, 4], dropout=0.2, NB_FILTERS=16):\n",
    "        super(TemporalTCNModel, self).__init__()\n",
    "        # Create the TCN part of the model\n",
    "        self.tcn = TCN(input_dim=input_dim, kernel_size=kernel_size, dilation_list=dilation_list, dropout=dropout, out_channels=NB_FILTERS)\n",
    "        # Define a 1x1 convolutional layer as a classifier\n",
    "        self.classifier = nn.Conv1d(NB_FILTERS, num_classes, kernel_size=1)\n",
    "        # Define a sigmoid activation function for the final output\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the TCN\n",
    "        x = self.tcn(x)\n",
    "        # Permute to (batch_size, channels, seq_len) for the classifier\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Apply the classifier\n",
    "        x = self.classifier(x)\n",
    "        # Permute back to (batch_size, seq_len, channels) for final output\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "# Function to create and return the model, moved to the given device\n",
    "def get_model(device, input_dim=3, num_classes=2, kernel_size=5, dilation_list=[1, 2, 4], dropout=0.2):\n",
    "    model = TemporalTCNModel(input_dim, num_classes, kernel_size, dilation_list, dropout, NB_FILTERS=16)\n",
    "    return model.to(device)\n",
    "\n",
    "# Get the model and move it to the specified device\n",
    "model = get_model(configuration.device)\n",
    "\n",
    "\"\"\" for inputs, labels in test_loader_fullwalk:\n",
    "        summary(model.to(torch.device(\"cpu\")),inputs.to(torch.device(\"cpu\"),dtype=torch.float32), depth=10)\n",
    "        model_graph = draw_graph(model.to(torch.device(\"cpu\")) , inputs.to(torch.device(\"cpu\"),dtype=torch.float32), device='meta', save_graph=True, filename='model_temporal_graph', depth=10)\n",
    "        break \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.autonotebook import tqdm\n",
    "import itertools\n",
    "import configuration\n",
    "import utilities  # Assuming utilities is a module containing required functions\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to separate sequences and labels.\n",
    "    \"\"\"\n",
    "    sequences = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    return sequences, labels\n",
    "\n",
    "\n",
    "def train_model(batch_size, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Train the model with the given hyperparameters and save it.\n",
    "\n",
    "    Args:\n",
    "    batch_size (int): Size of the batches used for training.\n",
    "    learning_rate (float): Learning rate for the optimizer.\n",
    "    epochs (int): Number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "    float: The average validation loss over all epochs.\n",
    "    str: Filename where the model is saved.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(11))\n",
    "    val_loss_overall = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=False):\n",
    "        model.train()\n",
    "        split_count = 0\n",
    "        val_loss_epoch = 0\n",
    "\n",
    "        for train_index, val_index in configuration.group_kfold.split(X, y, ids):\n",
    "            split_count += 1\n",
    "\n",
    "            # Split the data into training and validation sets\n",
    "            # stack in respect window_size\n",
    "            X_train = [X[i] for i in train_index]\n",
    "            X_train = [\n",
    "                torch.stack(X_train[i : i + configuration.window_size])\n",
    "                for i in range(0, len(X_train), configuration.window_size)\n",
    "            ]\n",
    "\n",
    "            X_val = [X[i] for i in val_index]\n",
    "            X_val = [\n",
    "                torch.stack(X_val[i : i + configuration.window_size])\n",
    "                for i in range(0, len(X_val), configuration.window_size)\n",
    "            ]\n",
    "\n",
    "            y_train = [y[i] for i in train_index]\n",
    "            y_train = [\n",
    "                torch.stack(y_train[i : i + configuration.window_size])\n",
    "                for i in range(0, len(y_train), configuration.window_size)\n",
    "            ]\n",
    "\n",
    "            y_val = [y[i] for i in val_index]\n",
    "            y_val = [\n",
    "                torch.stack(y_val[i : i + configuration.window_size])\n",
    "                for i in range(0, len(y_val), configuration.window_size)\n",
    "            ]\n",
    "\n",
    "             # Create TensorDatasets\n",
    "            train_dataset = utilities.CustomDataset(X_train, y_train)\n",
    "            val_dataset = utilities.CustomDataset(X_val, y_val)\n",
    "\n",
    "            # Create DataLoaders\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, batch_size=batch_size, shuffle=True\n",
    "            )\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            total_train_loss_split = 0\n",
    "            for sequences_batch, labels_batch in train_loader:\n",
    "                model.train()\n",
    "\n",
    "                # Transfer to GPU if available\n",
    "                sequences_batch = sequences_batch.to(configuration.device)\n",
    "                labels_batch = labels_batch.to(configuration.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(sequences_batch)\n",
    "                loss = loss_fn(output, labels_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss_split += loss.item()\n",
    "\n",
    "            train_loss_split = total_train_loss_split / len(train_loader)\n",
    "\n",
    "            # Validate the model\n",
    "            model.eval()\n",
    "            total_val_loss_split = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences_batch, labels_batch in val_loader:\n",
    "                    \n",
    "                    # Transfer to GPU if available\n",
    "                    sequences_batch = sequences_batch.to(configuration.device)\n",
    "                    labels_batch = labels_batch.to(configuration.device)\n",
    "\n",
    "                    output = model(sequences_batch)\n",
    "                    loss = loss_fn(output, labels_batch)\n",
    "                    total_val_loss_split += loss.item()\n",
    "\n",
    "            avg_val_loss_split = total_val_loss_split / len(val_loader)\n",
    "            val_loss_epoch += avg_val_loss_split\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs} Split {split_count}, Training Loss: {train_loss_split}, Validation Loss: {avg_val_loss_split}, Difference: {train_loss_split - avg_val_loss_split}\"\n",
    "            )\n",
    "\n",
    "        val_loss_epoch /= split_count\n",
    "        val_loss_overall += val_loss_epoch\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Mean Validation Loss: {val_loss_epoch}\")\n",
    "\n",
    "    val_loss_overall /= epochs\n",
    "\n",
    "    # Save the model with a unique filename\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    model_filename = (\n",
    "        f\"checkpoints/model_temporal_bs{batch_size}_lr{learning_rate}_epochs{epochs}.pt\"\n",
    "    )\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "    return val_loss_overall, model_filename\n",
    "\n",
    "\n",
    "# Hyperparameter grid\n",
    "batch_size_options = [4, 8, 12]\n",
    "learning_rate_options = [1e-3, 1e-4, 1e-5]\n",
    "epochs_options = [10, 30, 75]\n",
    "\n",
    "# Placeholder for storing performance metrics along with hyperparameters and filenames\n",
    "results = []\n",
    "\n",
    "# Loop over the parameter grid\n",
    "for batch_size, learning_rate, epochs in itertools.product(batch_size_options, learning_rate_options, epochs_options):\n",
    "    print(f\"Training model with batch size={batch_size}, learning rate={learning_rate}, epochs={epochs}\")\n",
    "\n",
    "    model_performance, model_filename = train_model(batch_size, learning_rate, epochs)\n",
    "    results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"performance\": model_performance,\n",
    "        \"filename\": model_filename\n",
    "    })\n",
    "    print(results)\n",
    "\n",
    "# Select the best model\n",
    "best_model = min(results, key=lambda x: x[\"performance\"])\n",
    "print(\"Best model parameters and performance:\", best_model)\n",
    "print(results)\n",
    "\n",
    "# Optional: Train with specific parameters if required\n",
    "# val_loss_overall, model_filename = train_model(12, 0.001, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import torch\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import configuration\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# Load Example Data from Pickle (only for testing not for performance evaluation)\n",
    "with open('example_data/testing_fullwalk_examples_temporal.pkl', 'rb') as f:\n",
    "    test_loader_fullwalk_examples = pickle.load(f)\n",
    "    test_loader_fullwalk = DataLoader(test_loader_fullwalk_examples)\n",
    "    \n",
    "    test_ids_fullwalk = [[1,1],[2,2],[3,3]]\n",
    "\n",
    "# Define model path manually (optional)\n",
    "model_filename = 'checkpoints/model_temporal_bs12_lr0.001_epochs30_freezing.pt'\n",
    "\n",
    "# Load the model state from the specified checkpoint and set it to evaluation mode\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "model.eval()\n",
    "\n",
    "# Initialize data iterator and other global variables\n",
    "data_iterator = iter(test_loader_fullwalk)\n",
    "current_index = -1\n",
    "total_batches = len(test_loader_fullwalk)  # Assuming this is known or calculated\n",
    "color_ic_fc = [\"black\", \"orange\"]\n",
    "break_by_error = False\n",
    "window_first_ic_matching = 20\n",
    "\n",
    "def select_gt_pd(logits_torch, true_steps):\n",
    "    \"\"\"Select ground truth and predicted steps (IC and FC) from logits and true steps.\"\"\"\n",
    "    global break_by_error, current_index\n",
    "    \n",
    "    # Transform logits through sigmoid\n",
    "    sigmoid_logits = torch.sigmoid(logits_torch)  \n",
    "\n",
    "    # Rough estimate peak finding of predicted values IC / FC\n",
    "    rough_peaks = {0: [], 1: []}\n",
    "    for class_idx in range(sigmoid_logits.shape[1]):\n",
    "        peaks, _ = find_peaks(\n",
    "            sigmoid_logits[:, class_idx], \n",
    "            distance=configuration.rough_estimate_min_peak_distance\n",
    "        )\n",
    "        rough_peaks[class_idx] = peaks\n",
    "\n",
    "    ic_pd_rough = rough_peaks[0]\n",
    "    fc_pd_rough = rough_peaks[1]\n",
    "\n",
    "    # Delete FCs before ICs\n",
    "    while fc_pd_rough[0] < ic_pd_rough[0]:\n",
    "        fc_pd_rough = fc_pd_rough[1:]\n",
    "\n",
    "    # GT Calculations\n",
    "    ic_gt_selected = np.where(true_steps[:, 0] == 1)[0]\n",
    "    fc_gt_selected = np.where(true_steps[:, 1] == 1)[0]\n",
    "\n",
    "    # Remove last FC from GT when after last IC\n",
    "    if fc_gt_selected[-1] > ic_gt_selected[-1]:\n",
    "        fc_gt_selected = fc_gt_selected[:-1]\n",
    "\n",
    "    # PD Calculations\n",
    "    fc_pd_selected = []\n",
    "    ic_pd_selected = []\n",
    "\n",
    "    ic_pd_rough_copy = ic_pd_rough.copy()\n",
    "    fc_pd_rough_copy = fc_pd_rough.copy()\n",
    "\n",
    "    # Find first best matching IC\n",
    "    i_first_selected = 0\n",
    "    i_first_select = False\n",
    "\n",
    "    while not i_first_select:\n",
    "        if abs(ic_pd_rough_copy[i_first_selected] - ic_gt_selected[0]) < abs(\n",
    "            ic_pd_rough_copy[i_first_selected + 1] - ic_gt_selected[0]\n",
    "        ):\n",
    "            i_first_select = True\n",
    "            ic_pd_selected.append(ic_pd_rough_copy[i_first_selected])\n",
    "        else:\n",
    "            i_first_selected += 1\n",
    "\n",
    "    # Trim rough to the first matching IC\n",
    "    ic_pd_rough_copy = ic_pd_rough_copy[i_first_selected:]\n",
    "    ic_range_start = ic_pd_rough_copy[0]\n",
    "    ic_pd_rough_copy = ic_pd_rough_copy[1:]\n",
    "\n",
    "    while len(ic_pd_rough_copy) > 0 and len(fc_pd_rough_copy) > 0:\n",
    "        if len(ic_pd_rough_copy) == 0:\n",
    "            break\n",
    "\n",
    "        # Look for next possible IC\n",
    "        ic_range_stop = None\n",
    "\n",
    "        while ic_range_stop is None:\n",
    "            if len(ic_pd_rough_copy) == 0:\n",
    "                ic_range_stop = len(logits_torch)\n",
    "                break\n",
    "            \n",
    "            ic_range_stop_tmp = ic_pd_rough_copy[0]\n",
    "\n",
    "            # Next IC which is after the next FC\n",
    "            if ic_range_stop_tmp > ic_range_start and ic_range_stop_tmp > fc_pd_rough_copy[0]:\n",
    "                ic_range_stop = ic_range_stop_tmp\n",
    "                break\n",
    "\n",
    "            ic_pd_rough_copy = ic_pd_rough_copy[1:]  # like pop()\n",
    "\n",
    "        # Peak for FC in range of ic_range_start / ic_range_stop\n",
    "        peak_fc_in_icrange, _ = find_peaks(\n",
    "            torch.sigmoid(logits_torch[ic_range_start:ic_range_stop, 1]),\n",
    "            distance=ic_range_stop - ic_range_start,\n",
    "            height=0.1,\n",
    "        )\n",
    "\n",
    "        if len(peak_fc_in_icrange) > 1:\n",
    "            break_by_error = True\n",
    "            print(\"handle more than one PEAK for IC\")\n",
    "\n",
    "        elif len(peak_fc_in_icrange) == 1:\n",
    "            peak_fc_in_icrange = ic_range_start + peak_fc_in_icrange[0]\n",
    "\n",
    "        elif len(peak_fc_in_icrange) == 0:\n",
    "            peak_fc_in_icrange = fc_pd_rough_copy[0]  # Fallback to rough estimate if not found\n",
    "\n",
    "        fc_pd_selected.append(peak_fc_in_icrange)\n",
    "\n",
    "        # Peak for IC\n",
    "        fc_range_start = peak_fc_in_icrange\n",
    "        fc_range_stop = None\n",
    "\n",
    "        while fc_range_stop is None:\n",
    "            if len(fc_pd_rough_copy) == 0:\n",
    "                fc_range_stop = len(logits_torch)\n",
    "                break\n",
    "        \n",
    "            fc_range_stop_tmp = fc_pd_rough_copy[0]\n",
    "\n",
    "            if fc_range_stop_tmp > fc_range_start and fc_range_stop_tmp > ic_pd_rough_copy[0]:\n",
    "                fc_range_stop = fc_range_stop_tmp\n",
    "                break\n",
    "\n",
    "            fc_pd_rough_copy = fc_pd_rough_copy[1:]  # like pop()\n",
    "\n",
    "        peak_ic_in_fcrange, _ = find_peaks(\n",
    "            torch.sigmoid(logits_torch[fc_range_start:fc_range_stop, 0]),\n",
    "            distance=fc_range_stop - fc_range_start,\n",
    "            height=0.1,\n",
    "        )\n",
    "\n",
    "        if len(peak_ic_in_fcrange) > 1:\n",
    "            break_by_error = True\n",
    "            print(\"handle more than one PEAK for FC\")\n",
    "\n",
    "        elif len(peak_ic_in_fcrange) == 1:\n",
    "            peak_ic_in_fcrange = fc_range_start + peak_ic_in_fcrange[0]\n",
    "\n",
    "        elif len(peak_ic_in_fcrange) == 0:\n",
    "            try:\n",
    "                peak_ic_in_fcrange = ic_pd_rough_copy[0]\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        ic_pd_rough_copy = ic_pd_rough_copy[1:]  # like pop\n",
    "        ic_pd_selected.append(peak_ic_in_fcrange)\n",
    "\n",
    "        # Clean up arrays for next cycle\n",
    "        ic_range_start = peak_ic_in_fcrange\n",
    "\n",
    "    # Return results of IC and FC calculations\n",
    "    return (\n",
    "        ic_pd_rough,\n",
    "        fc_pd_rough,\n",
    "        ic_pd_selected,\n",
    "        fc_pd_selected,\n",
    "        ic_gt_selected,\n",
    "        fc_gt_selected,\n",
    "    )\n",
    "\n",
    "def update_status_label(current_index, total_batches):\n",
    "    \"\"\"Update the status label with current batch information.\"\"\"\n",
    "    status_label.value = f\"Batch: {current_index + 1}/{total_batches} ID:{test_ids_fullwalk[current_index]}\"\n",
    "\n",
    "def plot_data(sample_sequence, true_steps, logits):\n",
    "    \"\"\"Plot accelerometer data and step detection results.\"\"\"\n",
    "    # Convert logits for uniform handling\n",
    "    logits_torch = torch.squeeze(logits).cpu()\n",
    "    logits = np.array(logits_torch)\n",
    "    true_steps = true_steps.cpu().numpy().squeeze()\n",
    "    time_steps = range(sample_sequence.size(1))\n",
    "    accelerometer_data = sample_sequence.cpu().numpy().squeeze()\n",
    "\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n",
    "    fig.suptitle(\"Example Step Detection\", fontsize=16)\n",
    "\n",
    "    if logits.ndim == 1:\n",
    "        logits = logits.reshape(-1, 1)\n",
    "    time_steps = np.arange(logits.shape[0])\n",
    "\n",
    "    for i, axis in enumerate([\"X\", \"Y\", \"Z\"]):\n",
    "        axes[0].plot(time_steps, accelerometer_data[:, i], label=f\"{axis}-axis\")\n",
    "    axes[0].set_title(\"Accelerometer Data\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    (\n",
    "        ic_pd_rough,\n",
    "        fc_pd_rough,\n",
    "        ic_pd_gaitcycle_conform,\n",
    "        fc_pd_gaitcycle_conform,\n",
    "        ic_gts_selected,\n",
    "        fc_gts_selected,\n",
    "    ) = select_gt_pd(logits_torch, true_steps)\n",
    "\n",
    "    axes[1].set_title(\"Step Detection / Ground truth\")\n",
    "    axes[1].set_xlim(axes[0].get_xlim())\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].set_ylabel(\"Ground truth\")\n",
    "\n",
    "    ic_gts = np.where(true_steps[:, 0] == 1)[0]\n",
    "    fc_gts = np.where(true_steps[:, 1] == 1)[0]\n",
    "\n",
    "    for ic_gt in ic_gts:\n",
    "        axes[1].axvline(x=ic_gt, color=color_ic_fc[0])\n",
    "\n",
    "    for peak in ic_gts_selected:\n",
    "        axes[1].plot(peak, 0.95, \"v\", markersize=10, color=color_ic_fc[0], alpha=0.5)\n",
    "\n",
    "    for fc_gt in fc_gts:\n",
    "        axes[1].axvline(x=fc_gt, color=color_ic_fc[1])\n",
    "\n",
    "    for peak in fc_gts_selected:\n",
    "        axes[1].plot(peak, 0.95, \"v\", markersize=10, color=color_ic_fc[1], alpha=0.5)\n",
    "\n",
    "    for peak in ic_pd_rough:\n",
    "        axes[3].axvline(x=peak, linestyle=\":\", color=color_ic_fc[0])\n",
    "        axes[2].axvline(x=peak, linestyle=\":\", color=color_ic_fc[0])\n",
    "        axes[1].axvline(x=peak, linestyle=\":\", color=color_ic_fc[0])\n",
    "        axes[0].axvline(x=peak, linestyle=\":\", color=color_ic_fc[0])\n",
    "\n",
    "    for peak in fc_pd_rough:\n",
    "        axes[3].axvline(x=peak, linestyle=\":\", color=color_ic_fc[1])\n",
    "        axes[2].axvline(x=peak, linestyle=\":\", color=color_ic_fc[1])\n",
    "        axes[1].axvline(x=peak, linestyle=\":\", color=color_ic_fc[1])\n",
    "        axes[0].axvline(x=peak, linestyle=\":\", color=color_ic_fc[1])\n",
    "\n",
    "    for peak in ic_pd_gaitcycle_conform:\n",
    "        axes[1].plot(peak, 0.05, \"^\", markersize=10, color=color_ic_fc[0], alpha=0.5)\n",
    "\n",
    "    for peak in fc_pd_gaitcycle_conform:\n",
    "        axes[1].plot(peak, 0.05, \"^\", markersize=10, color=color_ic_fc[1], alpha=0.5)\n",
    "\n",
    "    axes[2].plot(time_steps, logits[:, 0], label=f\"IC Logits\", color=color_ic_fc[0])\n",
    "    axes[2].plot(time_steps, logits[:, 1], label=f\"FC Logits\", color=color_ic_fc[1])\n",
    "    axes[2].set_title(\"Probability\")\n",
    "    axes[2].set_ylabel(\"Value\")\n",
    "\n",
    "    for class_idx in range(logits.shape[1]):\n",
    "        sigmoid_logits = torch.sigmoid(\n",
    "            logits_torch[:, class_idx]\n",
    "        )  # Transform logits through sigmoid\n",
    "        axes[3].plot(\n",
    "            time_steps,\n",
    "            sigmoid_logits,\n",
    "            label=f\"Class {class_idx} Sigmoid\",\n",
    "            color=color_ic_fc[class_idx],\n",
    "        )\n",
    "    axes[3].set_title(\"Logits with Sigmoid Function\")\n",
    "    axes[3].set_xlabel(\"Frames\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_and_plot(index_change):\n",
    "    \"\"\"Load data and plot based on index change.\"\"\"\n",
    "    global current_index, data_iterator\n",
    "    current_index += index_change\n",
    "    try:\n",
    "        sample_sequence, true_steps = next(data_iterator)\n",
    "    except StopIteration:\n",
    "        # Reset the iterator\n",
    "        data_iterator = iter(test_loader_fullwalk)\n",
    "        sample_sequence, true_steps = next(data_iterator)\n",
    "        if index_change < 0:\n",
    "            for _ in range(len(test_loader_fullwalk) - 1):\n",
    "                sample_sequence, true_steps = next(data_iterator)\n",
    "    sample_sequence = sample_sequence.to(configuration.device, dtype=torch.float32)\n",
    "    true_steps = true_steps.to(configuration.device, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(sample_sequence)\n",
    "    \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    update_status_label(current_index, total_batches)\n",
    "    plot_data(sample_sequence, true_steps, logits)\n",
    "    display(widgets.VBox([status_label, buttons]))\n",
    "\n",
    "# Buttons for navigation\n",
    "prev_button = widgets.Button(description=\"Previous\")\n",
    "next_button = widgets.Button(description=\"Next\")\n",
    "\n",
    "def on_prev_button_clicked(b):\n",
    "    \"\"\"Move to the previous item.\"\"\"\n",
    "    load_and_plot(-1)\n",
    "\n",
    "def on_next_button_clicked(b):\n",
    "    \"\"\"Move to the next item.\"\"\"\n",
    "    load_and_plot(1)\n",
    "\n",
    "prev_button.on_click(on_prev_button_clicked)\n",
    "next_button.on_click(on_next_button_clicked)\n",
    "\n",
    "buttons = widgets.HBox([prev_button, next_button])\n",
    "status_label = widgets.Label()\n",
    "display(widgets.VBox([status_label, buttons]))\n",
    "\n",
    "# Update status label initially\n",
    "update_status_label(current_index, total_batches)\n",
    "\n",
    "# Load and plot the first batch\n",
    "load_and_plot(1)\n",
    "\n",
    "#for i in range(1, total_batches):\n",
    "#    load_and_plot(1)\n",
    "#    if break_by_error:\n",
    "#       break_by_error = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_statistics\n",
    "\n",
    "\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Initialize dictionaries for metrics and counts, separated by class\n",
    "# Metrics for single step analysis\n",
    "\n",
    "class_metrics = {\n",
    "    0: {\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"misplacement_rel\": [],\n",
    "    },\n",
    "    1: {\n",
    "        \"accuracy\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"misplacement_rel\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class_counts = {\n",
    "    0: {\"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []},\n",
    "    1: {\"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []},\n",
    "}\n",
    "\n",
    "\n",
    "gt_pd_storage = {\"stride\": {}, \"swing\": {}, \"double\": {}}\n",
    "\n",
    "todelete = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    count_analysing_ic_fc = 0\n",
    "\n",
    "    count_act_dataset = -1\n",
    "\n",
    "    # Loop test_loader_fullwalk\n",
    "\n",
    "    for inputs, labels in test_loader_fullwalk:\n",
    "\n",
    "        count_act_dataset += 1\n",
    "\n",
    "        # predict outputs\n",
    "        outputs = model(inputs.to(configuration.device, dtype=torch.float32))\n",
    "\n",
    "        # move targets to cpu\n",
    "        logits_torch = outputs.cpu().squeeze()\n",
    "        true_steps = labels.cpu().squeeze()\n",
    "\n",
    "        # get selected and rough ICs\n",
    "        (\n",
    "            ic_pd_rough,\n",
    "            fc_pd_rough,\n",
    "            ic_pd_selected,\n",
    "            fc_pd_selected,\n",
    "            ic_gt_selected,\n",
    "            fc_gt_selected,\n",
    "        ) = select_gt_pd(logits_torch, true_steps)\n",
    "\n",
    "        # Convert result frames with events numbers to \"ones\" frames\n",
    "        ic_predicted_ones = np.zeros_like(true_steps[:, 0])\n",
    "        ic_predicted_ones[ic_pd_rough] = 1\n",
    "        ic_gt_ones = np.zeros_like(true_steps[:, 0])\n",
    "        ic_gt_ones[ic_gt_selected] = 1\n",
    "\n",
    "        # Calculate with rough_estimates for ICs\n",
    "        accuracy, precision, recall, f1_score, TP, TN, FP, FN = (\n",
    "            custom_statistics.calculate_metrics_with_tolerance(\n",
    "                ic_predicted_ones, ic_gt_ones\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Store metrics and counts separately for each class\n",
    "        class_metrics[0][\"accuracy\"].append(accuracy)\n",
    "        class_metrics[0][\"precision\"].append(precision)\n",
    "        class_metrics[0][\"recall\"].append(recall)\n",
    "        class_metrics[0][\"f1_score\"].append(f1_score)\n",
    "        class_counts[0][\"TP\"].append(TP)\n",
    "        class_counts[0][\"TN\"].append(TN)\n",
    "        class_counts[0][\"FP\"].append(FP)\n",
    "        class_counts[0][\"FN\"].append(FN)\n",
    "\n",
    "        # Convert result frames with events numbers to \"ones\" frames\n",
    "        fc_predfcted_ones = np.zeros_like(true_steps[:, 1])\n",
    "        fc_predfcted_ones[fc_pd_rough] = 1\n",
    "        fc_gt_ones = np.zeros_like(true_steps[:, 1])\n",
    "        fc_gt_ones[fc_gt_selected] = 1\n",
    "\n",
    "        accuracy, precision, recall, f1_score, TP, TN, FP, FN = (\n",
    "            custom_statistics.calculate_metrics_with_tolerance(\n",
    "                fc_predfcted_ones, fc_gt_ones\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Store metrics and counts separately for each class\n",
    "        class_metrics[1][\"accuracy\"].append(accuracy)\n",
    "        class_metrics[1][\"precision\"].append(precision)\n",
    "        class_metrics[1][\"recall\"].append(recall)\n",
    "        class_metrics[1][\"f1_score\"].append(f1_score)\n",
    "        class_counts[1][\"TP\"].append(TP)\n",
    "        class_counts[1][\"TN\"].append(TN)\n",
    "        class_counts[1][\"FP\"].append(FP)\n",
    "        class_counts[1][\"FN\"].append(FN)\n",
    "\n",
    "        # Calculate mean metrics and total counts for each class\n",
    "        mean_metrics = {}\n",
    "        total_counts = {}\n",
    "\n",
    "        # Calculations for IC\n",
    "        if len(ic_pd_selected) == len(ic_gt_selected):\n",
    "\n",
    "            # calculate misplacement\n",
    "            misplacement_frames = ic_pd_selected - ic_gt_selected\n",
    "            misplacement_frames_relativ = np.mean(misplacement_frames)\n",
    "            class_metrics[0][\"misplacement_rel\"].append(misplacement_frames_relativ)\n",
    "\n",
    "        # Calculations for FC\n",
    "        if len(fc_pd_selected) == len(fc_gt_selected):\n",
    "\n",
    "            # calculate misplacement\n",
    "            misplacement_frames = fc_pd_selected - fc_gt_selected\n",
    "            misplacement_frames_relativ = np.mean(misplacement_frames)\n",
    "            class_metrics[1][\"misplacement_rel\"].append(misplacement_frames_relativ)\n",
    "\n",
    "        \"\"\"\n",
    "        Calculations using IC and FC\n",
    "        Stride Time\n",
    "        begin at IC 3 and match it to the first IC\n",
    "        cut the FC in respect to the maximum possible IC correlation (2 at the end does not have a matching IC)\n",
    "        \"\"\"\n",
    "        if len(ic_gt_selected) == len(ic_pd_selected) and len(fc_gt_selected) == len(\n",
    "            fc_pd_selected\n",
    "        ):\n",
    "\n",
    "            # Stride Time\n",
    "            # ICn+2 - ICn\n",
    "            stride_frames_predicted = (\n",
    "                ic_pd_selected[2:] - np.roll(ic_pd_selected, 2)[2:]\n",
    "            )\n",
    "\n",
    "            stride_frames_gt = ic_gt_selected[2:] - np.roll(ic_gt_selected, 2)[2:]\n",
    "            count_analysing_ic_fc += 1\n",
    "\n",
    "            if test_ids_fullwalk[count_act_dataset] not in gt_pd_storage[\"stride\"]:\n",
    "                gt_pd_storage[\"stride\"][test_ids_fullwalk[count_act_dataset]] = {\n",
    "                    \"gt\": {\n",
    "                        \"slow\": [],\n",
    "                        \"regular\": [],\n",
    "                        \"fast\": [],\n",
    "                        \"slow_walks\": [],\n",
    "                        \"regular_walks\": [],\n",
    "                        \"fast_walks\": [],\n",
    "                    },\n",
    "                    \"pd\": {\n",
    "                        \"slow\": [],\n",
    "                        \"regular\": [],\n",
    "                        \"fast\": [],\n",
    "                        \"slow_walks\": [],\n",
    "                        \"regular_walks\": [],\n",
    "                        \"fast_walks\": [],\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            gt_pd_storage[\"stride\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                walk_speed[count_act_dataset]\n",
    "            ].extend(stride_frames_gt)\n",
    "\n",
    "            gt_pd_storage[\"stride\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                walk_speed[count_act_dataset]\n",
    "            ].extend(stride_frames_predicted)\n",
    "\n",
    "            gt_pd_storage[\"stride\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                walk_speed[count_act_dataset] + \"_walks\"\n",
    "            ].append(stride_frames_gt)\n",
    "\n",
    "            gt_pd_storage[\"stride\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                walk_speed[count_act_dataset] + \"_walks\"\n",
    "            ].append(stride_frames_predicted)\n",
    "\n",
    "            # Swing Time\n",
    "            swing_frames_predicted = np.array(ic_pd_selected[1:]) - np.array(\n",
    "                fc_pd_selected[: len(ic_pd_selected[1:])]\n",
    "            )\n",
    "            swing_frames_gt = np.array(ic_gt_selected[1:]) - np.array(\n",
    "                fc_gt_selected[: len(ic_gt_selected[1:])]\n",
    "            )\n",
    "            if len(swing_frames_predicted) == len(swing_frames_gt):\n",
    "\n",
    "                # alles unter 20% < löschen\n",
    "\n",
    "                if all(\n",
    "                    x > 20 for x in ((swing_frames_gt[1:] / stride_frames_gt) * 100)\n",
    "                ):\n",
    "\n",
    "                    if (\n",
    "                        test_ids_fullwalk[count_act_dataset]\n",
    "                        not in gt_pd_storage[\"swing\"]\n",
    "                    ):\n",
    "\n",
    "                        gt_pd_storage[\"swing\"][test_ids_fullwalk[count_act_dataset]] = {\n",
    "                            \"gt\": {\n",
    "                                \"slow\": [],\n",
    "                                \"regular\": [],\n",
    "                                \"fast\": [],\n",
    "                                \"slow_walks\": [],\n",
    "                                \"regular_walks\": [],\n",
    "                                \"fast_walks\": [],\n",
    "                            },\n",
    "                            \"pd\": {\n",
    "                                \"slow\": [],\n",
    "                                \"regular\": [],\n",
    "                                \"fast\": [],\n",
    "                                \"slow_walks\": [],\n",
    "                                \"regular_walks\": [],\n",
    "                                \"fast_walks\": [],\n",
    "                            },\n",
    "                        }\n",
    "\n",
    "                    gt_pd_storage[\"swing\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                        walk_speed[count_act_dataset]\n",
    "                    ].extend(swing_frames_gt)\n",
    "\n",
    "                    gt_pd_storage[\"swing\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                        walk_speed[count_act_dataset]\n",
    "                    ].extend(swing_frames_predicted)\n",
    "\n",
    "                    gt_pd_storage[\"swing\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                        walk_speed[count_act_dataset] + \"_walks\"\n",
    "                    ].append(swing_frames_gt)\n",
    "                    gt_pd_storage[\"swing\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                        walk_speed[count_act_dataset] + \"_walks\"\n",
    "                    ].append(swing_frames_predicted)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(\"to delete\")\n",
    "\n",
    "                    todelete.append(walk_ids_fullwalk[count_act_dataset])\n",
    "\n",
    "            # Double support Time\n",
    "\n",
    "            doublesupport_pd_min_length = min(len(fc_pd_selected), len(ic_pd_selected))\n",
    "\n",
    "            doublesupport_frames_predicted = np.array(\n",
    "                fc_pd_selected[:doublesupport_pd_min_length]\n",
    "            ) - np.array(ic_pd_selected[:doublesupport_pd_min_length])\n",
    "\n",
    "            doublesupport_gt_min_length = min(len(fc_gt_selected), len(ic_gt_selected))\n",
    "\n",
    "            doublesupport_frames_gt = np.array(\n",
    "                fc_gt_selected[:doublesupport_pd_min_length]\n",
    "            ) - np.array(ic_gt_selected[:doublesupport_pd_min_length])\n",
    "\n",
    "            if len(doublesupport_frames_predicted) == len(doublesupport_frames_gt):\n",
    "\n",
    "                if all(\n",
    "                    x < 30\n",
    "                    for x in ((doublesupport_frames_gt[1:] / stride_frames_gt) * 100)\n",
    "                ):\n",
    "\n",
    "                    if (\n",
    "                        test_ids_fullwalk[count_act_dataset]\n",
    "                        not in gt_pd_storage[\"double\"]\n",
    "                    ):\n",
    "\n",
    "                        gt_pd_storage[\"double\"][\n",
    "                            test_ids_fullwalk[count_act_dataset]\n",
    "                        ] = {\n",
    "                            \"gt\": {\n",
    "                                \"slow\": [],\n",
    "                                \"regular\": [],\n",
    "                                \"fast\": [],\n",
    "                                \"slow_walks\": [],\n",
    "                                \"regular_walks\": [],\n",
    "                                \"fast_walks\": [],\n",
    "                            },\n",
    "                            \"pd\": {\n",
    "                                \"slow\": [],\n",
    "                                \"regular\": [],\n",
    "                                \"fast\": [],\n",
    "                                \"slow_walks\": [],\n",
    "                                \"regular_walks\": [],\n",
    "                                \"fast_walks\": [],\n",
    "                            },\n",
    "                        }\n",
    "\n",
    "                    gt_pd_storage[\"double\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                        walk_speed[count_act_dataset]\n",
    "                    ].extend(doublesupport_frames_gt)\n",
    "\n",
    "                    gt_pd_storage[\"double\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                        walk_speed[count_act_dataset]\n",
    "                    ].extend(doublesupport_frames_predicted)\n",
    "\n",
    "                    gt_pd_storage[\"double\"][test_ids_fullwalk[count_act_dataset]][\"gt\"][\n",
    "                        walk_speed[count_act_dataset] + \"_walks\"\n",
    "                    ].append(doublesupport_frames_gt)\n",
    "\n",
    "                    gt_pd_storage[\"double\"][test_ids_fullwalk[count_act_dataset]][\"pd\"][\n",
    "                        walk_speed[count_act_dataset] + \"_walks\"\n",
    "                    ].append(doublesupport_frames_predicted)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(\"to delete\")\n",
    "\n",
    "                    todelete.append(walk_ids_fullwalk[count_act_dataset])\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Statistics for IC / FC Classes\n",
    "\"\"\"\n",
    "\n",
    "print(\"============================================================================\")\n",
    "\n",
    "print(\"Statistic Results\")\n",
    "\n",
    "print(f\"analysed full walks: {count_analysing_ic_fc}\")\n",
    "\n",
    "print(\"============================================================================\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "for class_number in class_metrics:\n",
    "\n",
    "    mean_metrics[class_number] = {\n",
    "        metric: np.mean(values)\n",
    "        for metric, values in class_metrics[class_number].items()\n",
    "    }\n",
    "\n",
    "    total_counts[class_number] = {\n",
    "        count: np.sum(values) for count, values in class_counts[class_number].items()\n",
    "    }\n",
    "\n",
    "\n",
    "for class_number in range(2):\n",
    "\n",
    "    print(f\"CLASS:{class_number}\")\n",
    "\n",
    "    print(\"{:<10}                 {:<10}\".format(\"Parameter\", \"Value\"))\n",
    "\n",
    "    print(\"======================================\")\n",
    "\n",
    "    for key, value in mean_metrics[class_number].items():\n",
    "\n",
    "        print(\"{:<10}                 {:<10}\".format(key, value))\n",
    "\n",
    "    for key, value in total_counts[class_number].items():\n",
    "\n",
    "        print(\"{:<10}                 {:<10}\".format(key, value))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Statistics for Gaitparameters\n",
    "\"\"\"\n",
    "\n",
    "print(\"============================================================================\")\n",
    "\n",
    "print(\"Gaitparameter\")\n",
    "\n",
    "print(\"============================================================================\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "statistics = {\n",
    "    \"stride\": {\n",
    "        \"mean\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"cv\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"asymmetry\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"rmserel\": {\"slow\": {}, \"regular\": {}, \"fast\": {}},\n",
    "    },\n",
    "    \"swing\": {\n",
    "        \"mean\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"cv\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"asymmetry\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"rmserel\": {\"slow\": {}, \"regular\": {}, \"fast\": {}},\n",
    "    },\n",
    "    \"double\": {\n",
    "        \"mean\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"cv\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"asymmetry\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"rmserel\": {\"slow\": {}, \"regular\": {}, \"fast\": {}},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "for parameter in gt_pd_storage:\n",
    "\n",
    "    for proband in gt_pd_storage[parameter]:\n",
    "\n",
    "        for sensor in gt_pd_storage[parameter][proband]:\n",
    "\n",
    "            for speed in [\"slow\", \"regular\", \"fast\"]:\n",
    "\n",
    "                values = gt_pd_storage[parameter][proband][sensor][speed]\n",
    "\n",
    "                statistics[parameter][\"mean\"][sensor][speed].append(np.mean(values))\n",
    "\n",
    "                statistics[parameter][\"cv\"][sensor][speed].append(\n",
    "                    (np.std(values) / np.mean(values)) * 100\n",
    "                )\n",
    "\n",
    "                # Calculate RMSE for each parameter on proband level\n",
    "                if sensor == \"gt\":\n",
    "\n",
    "                    for values_gt_walk, values_pd_walk in zip(\n",
    "                        gt_pd_storage[parameter][proband][\"gt\"][speed + \"_walks\"],\n",
    "                        gt_pd_storage[parameter][proband][\"pd\"][speed + \"_walks\"],\n",
    "                    ):\n",
    "                        rmse = np.mean(\n",
    "                            np.sqrt(np.mean((values_gt_walk - values_pd_walk) ** 2))\n",
    "                        )\n",
    "                        relative_rmse = (rmse / np.mean(values_gt_walk)) * 100\n",
    "\n",
    "                        if proband not in statistics[parameter][\"rmserel\"][speed]:\n",
    "                            statistics[parameter][\"rmserel\"][speed][proband] = []\n",
    "\n",
    "                        statistics[parameter][\"rmserel\"][speed][proband].append(\n",
    "                            relative_rmse\n",
    "                        )\n",
    "\n",
    "                # Asymmetry\n",
    "                # Extract Left / Right\n",
    "\n",
    "                meanValue0 = np.array(values[1::2])\n",
    "\n",
    "                meanValue1 = np.array(values[0::2])\n",
    "\n",
    "                min_length = min(len(meanValue0), len(meanValue1))\n",
    "\n",
    "                meanValue0 = np.nanmean(meanValue0[:min_length])\n",
    "\n",
    "                meanValue1 = np.nanmean(meanValue1[:min_length])\n",
    "\n",
    "                if meanValue0 > meanValue1:\n",
    "\n",
    "                    asymmetrie = 100 * (1 - abs(meanValue1 / meanValue0))\n",
    "                else:\n",
    "\n",
    "                    asymmetrie = 100 * (1 - abs(meanValue0 / meanValue1))\n",
    "\n",
    "                statistics[parameter][\"asymmetry\"][sensor][speed].append(asymmetrie)\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "for parameter in statistics:\n",
    "\n",
    "    rmserel_values = {\"slow\": [], \"regular\": [], \"fast\": []}\n",
    "\n",
    "    for speed in statistics[parameter][\"rmserel\"]:\n",
    "        rmserel_values_tmp = []\n",
    "        for proband in statistics[parameter][\"rmserel\"][speed]:\n",
    "            rmserel_values_tmp.append(\n",
    "                np.mean(statistics[parameter][\"rmserel\"][speed][proband])\n",
    "            )\n",
    "\n",
    "        rmserel_values[speed] = rmserel_values_tmp\n",
    "\n",
    "        print(\n",
    "            f\"RMSE relative:: Parameter: {parameter}; Speed: {speed}; Probands: {len(rmserel_values_tmp)} ; Mean: {np.mean(rmserel_values_tmp):.4f}; Variance: {np.var(rmserel_values_tmp):.4f}; Std: {np.std(rmserel_values_tmp):.4f}\"\n",
    "        )\n",
    "\n",
    "    for speed, data in zip(rmserel_values, rmserel_values.values()):\n",
    "        shapiro_test = stats.shapiro(data)\n",
    "        print(\n",
    "            f\"Shapiro-Wilk Test {speed}: Statistic={shapiro_test.statistic:.4f}, p-value={shapiro_test.pvalue:.4f}\"\n",
    "        )\n",
    "\n",
    "    # Perform one-way ANOVA\n",
    "    f_val, p_val = scipy.stats.f_oneway(\n",
    "        rmserel_values[\"slow\"], rmserel_values[\"regular\"], rmserel_values[\"fast\"]\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Parameter: {parameter} ANOVA result: F-value = {f_val:.4f}, P-value = {p_val:.4f}\"\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(\n",
    "        rmserel_values.keys(),\n",
    "        [np.mean(values) for values in rmserel_values.values()],\n",
    "        yerr=[np.std(values) for values in rmserel_values.values()],\n",
    "    )\n",
    "    plt.xlabel(\"Speed\")\n",
    "    plt.ylabel(\"RMSE Relative\")\n",
    "    plt.ylim(0, 60)\n",
    "    plt.title(\"RMSE Relative for Different Speeds\")\n",
    "\n",
    "    # Save the plot as svg in the rmse_figures folder\n",
    "    plt.savefig(f\"rmse_figures/rmse_plot_{parameter}.svg\", format=\"svg\")\n",
    "\n",
    "    plt.show()\n",
    "print(\"here\")\n",
    "\n",
    "\n",
    "def standard_output(metric, parameter):\n",
    "\n",
    "    overall_gt = np.array(\n",
    "        statistics[metric][parameter][\"gt\"][\"fast\"]\n",
    "        + statistics[metric][parameter][\"gt\"][\"slow\"]\n",
    "        + statistics[metric][parameter][\"gt\"][\"regular\"]\n",
    "    )\n",
    "\n",
    "    overall_pd = np.array(\n",
    "        statistics[metric][parameter][\"pd\"][\"fast\"]\n",
    "        + statistics[metric][parameter][\"pd\"][\"slow\"]\n",
    "        + statistics[metric][parameter][\"pd\"][\"regular\"]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.scatter(overall_gt, overall_pd)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    print(\"============================================\")\n",
    "\n",
    "    print(\"Error, Correlation & Statistics\")\n",
    "\n",
    "    print(\"============================================\")\n",
    "\n",
    "    print(\"SLOW ============================================\")\n",
    "\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"slow\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"slow\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"REGULAR ============================================\")\n",
    "\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"regular\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"regular\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"FAST ============================================\")\n",
    "\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"fast\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"fast\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"OVERALL ============================================\")\n",
    "\n",
    "    print(custom_statistics.uniform_statistics(overall_gt, overall_pd))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "print(\"STRIDE\")\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "standard_output(\"stride\", \"mean\")\n",
    "\n",
    "standard_output(\"stride\", \"cv\")\n",
    "\n",
    "print(\"asymmetrie ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "standard_output(\"stride\", \"asymmetry\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "print(\"SWING\")\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "standard_output(\"swing\", \"mean\")\n",
    "\n",
    "standard_output(\"swing\", \"cv\")\n",
    "\n",
    "print(\"asymmetrie ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "standard_output(\"swing\", \"asymmetry\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "print(\"DOUBLE\")\n",
    "\n",
    "print(\n",
    "    \"================================================================================\"\n",
    ")\n",
    "\n",
    "standard_output(\"double\", \"mean\")\n",
    "\n",
    "standard_output(\"double\", \"cv\")\n",
    "\n",
    "print(\"asymmetrie ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "standard_output(\"double\", \"asymmetry\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequence-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
