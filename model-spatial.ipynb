{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Example Testing please run the Section \"Model Definition\" and \"Testing Stride Length\" / \"Testing Stride Width\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import utilities\n",
    "import configuration\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import math\n",
    "import scipy\n",
    "from pickle import dump\n",
    "\n",
    "# Group the dataframe by 'walk_id'\n",
    "groups = configuration.df.groupby(\"walk_id\")\n",
    "\n",
    "# ===========================================================================\n",
    "# Iterate through groups to create sequences and labels\n",
    "\n",
    "# Initialize empty lists to store sequences, labels, and IDs\n",
    "data_sequences = []\n",
    "data_labels = []\n",
    "data_ids = []\n",
    "walk_ids = []\n",
    "speeds = []\n",
    "\n",
    "dataset_number = 0\n",
    "\n",
    "count_gait_cycles = 0\n",
    "count_gait_cycles_slow = 0\n",
    "count_gait_cycles_regular = 0\n",
    "count_gait_cycles_fast = 0\n",
    "\n",
    "for name, group in groups:\n",
    "\n",
    "    # Extract the accelerometer data and other relevant columns\n",
    "    data = group[[\"acc_x\", \"acc_y\", \"acc_z\"]].to_numpy()  # Input data\n",
    "    HeelX = group[[\"HeelX\"]].to_numpy()\n",
    "    HeelY = group[[\"HeelY\"]].to_numpy()\n",
    "    events = group[[\"events\"]].to_numpy()\n",
    "\n",
    "    if group[\"sensor_side\"].iloc[0] == \"0_Right\" or group[\"sensor_side\"].iloc[0] == \"1_Left\":\n",
    "\n",
    "        # Identify Initial Contact (IC) events\n",
    "        IC = np.where(np.isin(events, [1, 2]))[0]\n",
    "\n",
    "        # Iterate through each IC event to create sequences and labels\n",
    "        \n",
    "        for i in range(0, len(IC) - 2):\n",
    "            count_gait_cycles += 1\n",
    "            seq = data[IC[i] : IC[i + 2], :]\n",
    "            seq = np.array(seq).T  # shape(3,n)\n",
    "\n",
    "            x_dist = HeelX[IC[i + 2]] - HeelX[IC[i]]\n",
    "            y_dist = np.abs(HeelY[IC[i + 2]] - HeelY[IC[i]])\n",
    "\n",
    "            # Ensure distances are positive\n",
    "            if x_dist < 0:\n",
    "                x_dist = -1 * x_dist\n",
    "                y_dist = -1 * y_dist\n",
    "\n",
    "            stride_length = np.abs(x_dist)\n",
    "\n",
    "            # Define the coordinates\n",
    "            A = np.array(\n",
    "                [HeelX[IC[i]], HeelY[IC[i]]]\n",
    "            ).squeeze()  # Point  A line-of-progression\n",
    "            B = np.array(\n",
    "                [HeelX[IC[i + 2]], HeelY[IC[i + 2]]]\n",
    "            ).squeeze()  # Point B line-of-progression\n",
    "            C = np.array(\n",
    "                [HeelX[IC[i + 1]], HeelY[IC[i + 1]]]\n",
    "            ).squeeze()  # Point C (D) Hell of different foot\n",
    "\n",
    "            # Step 1: Vector AB\n",
    "            AB = B - A\n",
    "\n",
    "            # Step 2: Unit vector in the direction of AB\n",
    "            u = AB / np.linalg.norm(AB)\n",
    "\n",
    "            # Step 3: Vector AC\n",
    "            AC = C - A\n",
    "\n",
    "            # Step 4: Projection of AC onto u\n",
    "            proj_AC_on_u = np.dot(AC, u) * u\n",
    "\n",
    "            # Step 5: Orthogonal vector from AC to the line AB\n",
    "            orthogonal_vector = AC - proj_AC_on_u\n",
    "\n",
    "            # Step 6: Length of the orthogonal vector\n",
    "            stride_width = np.linalg.norm(orthogonal_vector)\n",
    "\n",
    "            # Add the sequence to the list  \n",
    "            data_sequences.append(torch.tensor(seq, dtype=torch.float32))\n",
    "\n",
    "            # Add the base of support as a label\n",
    "            # data_labels.append(torch.tensor([stride_width], dtype=torch.float32))\n",
    "\n",
    "            # Add the stride length as a label\n",
    "            data_labels.append(torch.tensor([stride_length], dtype=torch.float32))\n",
    "\n",
    "            data_ids.append(group[\"id\"][group.first_valid_index()])  # len(samples)\n",
    "            walk_ids.append(group[\"walk_id\"][group.first_valid_index()])\n",
    "            speeds.extend([group[\"speed\"][group.first_valid_index()]])\n",
    "            \n",
    "            if group[\"speed\"][group.first_valid_index()] == \"slow\":\n",
    "                count_gait_cycles_slow += 1\n",
    "            elif group[\"speed\"][group.first_valid_index()] == \"regular\":\n",
    "                count_gait_cycles_regular += 1\n",
    "            elif group[\"speed\"][group.first_valid_index()] == \"fast\":\n",
    "                count_gait_cycles_fast += 1\n",
    "\n",
    "    dataset_number += 1\n",
    "\n",
    "print(f\"Gait cycles: {len(data_sequences)}\")#\n",
    "print(f\"Slow gait cycles: {count_gait_cycles_slow}\")\n",
    "print(f\"Regular gait cycles: {count_gait_cycles_regular}\")\n",
    "print(f\"Fast gait cycles: {count_gait_cycles_fast}\")\n",
    "\n",
    "# ===========================================================================\n",
    "# Stack data and labels\n",
    "data_sequences = utilities.pad_and_stack(\n",
    "    data_sequences\n",
    ")  # shape(samples,3,sequence_length)\n",
    "data_labels = torch.vstack(data_labels)  # shape(samples,1)\n",
    "\n",
    "# ===========================================================================\n",
    "# Split Datasets for training / unseen testing\n",
    "train_index, test_index = next(\n",
    "    configuration.group_split.split(data_sequences, data_labels, data_ids)\n",
    ")\n",
    "\n",
    "# ===========================================================================\n",
    "# Prepare training and test datasets\n",
    "X = data_sequences[[train_index]]\n",
    "X_test = data_sequences[[test_index]]\n",
    "\n",
    "y = data_labels[[train_index]]\n",
    "y_test = data_labels[[test_index]]\n",
    "\n",
    "ids = [data_ids[i] for i in train_index]\n",
    "\n",
    "ids_test_spatial = [data_ids[i] for i in test_index]\n",
    "walk_ids_test = [walk_ids[i] for i in test_index]\n",
    "walk_speed_test = [speeds[i] for i in test_index]\n",
    "# ===========================================================================\n",
    "# Setup scaler only with training data\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "x_np = X.numpy()\n",
    "\n",
    "# Reshape the array to 2D (necessary for the scaler)\n",
    "n_samples, n_channels, n_features = x_np.shape\n",
    "x_np_reshaped = x_np.reshape(-1, n_features)\n",
    "\n",
    "# Apply the RobustScaler\n",
    "scaler_data = RobustScaler().fit(x_np_reshaped)\n",
    "x_scaled_np_reshaped = scaler_data.transform(x_np_reshaped)\n",
    "\n",
    "# Save the scaler\n",
    "dump(scaler_data, open('checkpoints/scaler_spatial_input_stridelength.pkl', 'wb'))\n",
    "\n",
    "# Reshape the array back to its original shape\n",
    "x_scaled_np = x_scaled_np_reshaped.reshape(n_samples, n_channels, n_features)\n",
    "\n",
    "# Convert the scaled array back to a PyTorch tensor\n",
    "X = torch.from_numpy(x_scaled_np)\n",
    "\n",
    "# Scale the target data (labels)\n",
    "scaler_target = RobustScaler().fit(y)\n",
    "y = torch.tensor(scaler_target.transform(y))\n",
    "\n",
    "# Save the scaler\n",
    "dump(scaler_target, open('checkpoints/scaler_spatial_target_stridelength.pkl', 'wb'))\n",
    "\n",
    "# ===========================================================================\n",
    "# Create datasets for testing\n",
    "# scaling data\n",
    "x_np = X_test.numpy()\n",
    "n_samples, n_channels, n_features = x_np.shape\n",
    "x_np_reshaped = x_np.reshape(-1, n_features)\n",
    "x_scaled_np_reshaped = scaler_data.transform(x_np_reshaped)\n",
    "x_scaled_np = x_scaled_np_reshaped.reshape(n_samples, n_channels, n_features)\n",
    "X_test = torch.from_numpy(x_scaled_np)\n",
    "\n",
    "# scaling labels\n",
    "y_test = torch.tensor(scaler_target.transform(y_test))\n",
    "\n",
    "test_dataset = utilities.CustomDataset(X_test, y_test)\n",
    "\n",
    "# Get the first three examples from the test dataset\n",
    "testing_fullwalk_examples = [test_dataset[i] for i in range(3)]\n",
    "\n",
    "# Dump the testing_fullwalk_examples into a pickle file\n",
    "with open('example_data/testing_fullwalk_examples_spatial_stridelength.pkl', 'wb') as f:\n",
    "    dump(testing_fullwalk_examples, f)\n",
    "\n",
    "test_loader_fullwalk = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import configuration\n",
    "from torchsummary import summary\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('svg')\n",
    "graphviz.set_default_format('svg')\n",
    "\n",
    "# Define a custom layer to remove padding from the end of a sequence\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Remove the last 'chomp_size' elements from the sequence dimension\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "# Define a temporal block consisting of two convolutional layers with activation and dropout\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TCNBlock, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)  # Remove padding from the end of the sequence\n",
    "        self.relu1 = nn.ReLU()  # Activation function = rectified linear unit\n",
    "        self.dropout1 = nn.Dropout(dropout)  # Dropout for regularization\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)  # Remove padding from the end of the sequence\n",
    "        self.relu2 = nn.ReLU()  # Activation function = rectified linear unit\n",
    "        self.dropout2 = nn.Dropout(dropout)  # Dropout for regularization\n",
    "\n",
    "        # Sequence of layers in the block\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        \n",
    "        # Downsample if input and output channels do not match\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.init_weights()  # Initialize weights\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Initialize weights for convolutional layers\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)  # Forward pass through the block\n",
    "        res = x if self.downsample is None else self.downsample(x)  # Downsample if needed\n",
    "        return self.relu(out + res)  # Apply residual connection and activation\n",
    "\n",
    "# Define the Temporal Convolutional Network (TCN) consisting of multiple temporal blocks\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)  # Number of temporal blocks\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i  # Exponentially increasing dilation size\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            # Add temporal block to the network\n",
    "            layers += [TCNBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)  # Sequential container for the network\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # Forward pass through the network\n",
    "\n",
    "# Define the TCN model for gait spatial analysis\n",
    "class TCNGaitSpatial(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TCNGaitSpatial, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)  # Temporal convolutional network\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)  # Output shape: (batch_size, num_channels[-1], sequence_length)\n",
    "        y1_pooled = self.global_avg_pool(y1).squeeze(-1)  # Output shape: (batch_size, num_channels[-1])\n",
    "        y2 = self.linear(y1_pooled)  # Output shape: (batch_size, output_size)\n",
    "        return y2\n",
    "\n",
    "# Model Parameters\n",
    "input_size = 3  # Number of input channels\n",
    "output_size = 1  # Number of output channels\n",
    "num_channels = [16, 32, 64]  # Channel sizes for each layer\n",
    "kernel_size = 2  # Kernel size for convolutional layers\n",
    "dropout = 0.2  # Dropout rate\n",
    "\n",
    "# Instantiate and move the model to the specified device\n",
    "model = TCNGaitSpatial(input_size, output_size, num_channels, kernel_size, dropout).to(configuration.device)\n",
    "\n",
    "\"\"\" for inputs, labels in test_loader_fullwalk:\n",
    "        dataset_number += 1\n",
    "        # Move inputs and labels to the configured device\n",
    "        inputs, labels = inputs.to(configuration.device), labels.to(\n",
    "            configuration.device\n",
    "        )\n",
    "        summary(model,inputs, depth=10)\n",
    "        model_graph = draw_graph(model.to(torch.device(\"cpu\")) , inputs.to(torch.device(\"cpu\"),dtype=torch.float32), device='meta', save_graph=True, filename='model_spatial_graph', depth=10)\n",
    "        break \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import configuration\n",
    "import utilities  # Assuming utilities is a module containing required functions\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    sequences = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    return sequences, labels\n",
    "\n",
    "\n",
    "def train_model(batch_size, learning_rate, epochs):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    val_loss_overall = 0\n",
    "\n",
    "    log_dir = f\"logs/batch_size_{batch_size}_lr_{learning_rate}_epochs_{epochs}\"\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=False):\n",
    "        model.train()\n",
    "        split_count = 0\n",
    "        val_loss_epoch = 0\n",
    "\n",
    "        for train_index, val_index in configuration.group_kfold.split(X, y, ids):\n",
    "            split_count += 1\n",
    "\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            train_dataset = utilities.CustomDataset(X_train, y_train)\n",
    "            val_dataset = utilities.CustomDataset(X_val, y_val)\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                collate_fn=custom_collate_fn,\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn\n",
    "            )\n",
    "\n",
    "            total_train_loss_split = 0\n",
    "            for sequences_batch, labels_batch in train_loader:\n",
    "                model.train()\n",
    "\n",
    "                tensor_batch = utilities.pad_and_stack(sequences_batch).to(\n",
    "                    configuration.device\n",
    "                )\n",
    "                labels_batch = torch.squeeze(torch.vstack(labels_batch)).to(\n",
    "                    configuration.device, dtype=torch.float32\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = torch.squeeze(model(tensor_batch))\n",
    "                loss = loss_fn(output, labels_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss_split += loss.item()\n",
    "\n",
    "            train_loss_split = total_train_loss_split / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            total_val_loss_split = 0\n",
    "            with torch.no_grad():\n",
    "                for sequences_batch, labels_batch in val_loader:\n",
    "                    tensor_batch = utilities.pad_and_stack(sequences_batch).to(\n",
    "                        configuration.device\n",
    "                    )\n",
    "                    labels_batch = torch.squeeze(torch.vstack(labels_batch)).to(\n",
    "                        configuration.device\n",
    "                    )\n",
    "\n",
    "                    output = torch.squeeze(model(tensor_batch))\n",
    "                    loss = loss_fn(output, labels_batch)\n",
    "                    total_val_loss_split += loss.item()\n",
    "\n",
    "            avg_val_loss_split = total_val_loss_split / len(val_loader)\n",
    "            val_loss_epoch += avg_val_loss_split\n",
    "\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar('train_loss_split', train_loss_split, step=epoch)\n",
    "                tf.summary.scalar('val_loss_split', avg_val_loss_split, step=epoch)\n",
    "                tf.summary.scalar('loss_diff', train_loss_split - avg_val_loss_split, step=epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs} Split {split_count}, Training Loss: {train_loss_split}, Validation Loss: {avg_val_loss_split}, Difference: {train_loss_split - avg_val_loss_split}\"\n",
    "            )\n",
    "\n",
    "        val_loss_epoch /= split_count\n",
    "        val_loss_overall += val_loss_epoch\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('val_loss_epoch', val_loss_epoch, step=epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Mean Validation Loss: {val_loss_epoch}\")\n",
    "\n",
    "    val_loss_overall /= epochs\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    model_filename = (\n",
    "        f\"checkpoints/model_spatial_bs{batch_size}_lr{learning_rate}_epochs{epochs}.pt\"\n",
    "    )\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return val_loss_overall, model_filename\n",
    "\n",
    "\n",
    "# Hyperparameter grid\n",
    "batch_size_options = [4, 8, 12]\n",
    "learning_rate_options = [1e-3, 1e-4, 1e-5]\n",
    "epochs_options = [30, 75]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Create a summary writer for hyperparameter tuning results\n",
    "hp_summary_writer = tf.summary.create_file_writer(\"logs/hyperparameter_tuning\")\n",
    "\n",
    "for batch_size, learning_rate, epochs in itertools.product(batch_size_options, learning_rate_options, epochs_options):\n",
    "    print(f\"Training model with batch size={batch_size}, learning rate={learning_rate}, epochs={epochs}\")\n",
    "\n",
    "    model_performance, model_filename = train_model(batch_size, learning_rate, epochs)\n",
    "    results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"performance\": model_performance,\n",
    "        \"filename\": model_filename\n",
    "    })\n",
    "\n",
    "    with hp_summary_writer.as_default():\n",
    "        hp_metric = f\"batch_size_{batch_size}_lr_{learning_rate}_epochs_{epochs}\"\n",
    "        tf.summary.scalar(hp_metric, model_performance, step=0)\n",
    "\n",
    "    print(results)\n",
    "\n",
    "best_model = min(results, key=lambda x: x[\"performance\"])\n",
    "print(\"Best model parameters and performance:\", best_model)\n",
    "print(results)\n",
    "\n",
    "with hp_summary_writer.as_default():\n",
    "    tf.summary.text(\"best_model\", str(best_model), step=0)\n",
    "\n",
    "\n",
    "# Optional: Train with specific parameters if required\n",
    "# val_loss_overall, model_filename = train_model(1, 1e-03, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Stride Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Model filename to load\n",
    "model_filename = \"checkpoints/model_spatial_stridelength_bs1_lr1e-05_epochs30_freezing.pt\"\n",
    "\n",
    "# Scaler target\n",
    "scaler_target = pickle.load(open('checkpoints/scaler_spatial_target_stridelength.pkl', 'rb'))\n",
    "\n",
    "# Load the model state from the specified checkpoint and set it to evaluation mode\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "model.eval()\n",
    "\n",
    "# Load Example Data from Pickle (only for testing not for performance evaluation)\n",
    "with open('example_data/testing_fullwalk_examples_spatial_stridelength.pkl', 'rb') as f:\n",
    "    test_loader_fullwalk_examples = pickle.load(f)\n",
    "    test_loader_fullwalk = DataLoader(test_loader_fullwalk_examples)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataset_number = 0\n",
    "    for inputs, labels in test_loader_fullwalk:\n",
    "        dataset_number += 1\n",
    "        # Move inputs and labels to the configured device\n",
    "        inputs, labels = inputs.to(configuration.device), labels.to(\n",
    "            configuration.device\n",
    "        )\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Detach outputs from the computation graph and move to CPU for plotting\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        print(f\"Dataset {dataset_number}\")\n",
    "        print(f\"Predicted Stride Length: {scaler_target.inverse_transform(outputs[0][0].reshape(-1, 1))}\")\n",
    "        print(f\"Actual Stride Length: {scaler_target.inverse_transform(labels[0][0].reshape(-1, 1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Stride Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Model filename to load\n",
    "model_filename = \"checkpoints/model_spatial_stridewidth_bs1_lr0.001_epochs15_freezing.pt\"\n",
    "\n",
    "# Scaler target\n",
    "scaler_target = pickle.load(open('checkpoints/scaler_spatial_target_stridewidth.pkl', 'rb'))\n",
    "\n",
    "# Load the model state from the specified checkpoint and set it to evaluation mode\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "model.eval()\n",
    "\n",
    "# Load Example Data from Pickle (only for testing not for performance evaluation)\n",
    "with open('example_data/testing_fullwalk_examples_spatial_stridewidth.pkl', 'rb') as f:\n",
    "    test_loader_fullwalk_examples = pickle.load(f)\n",
    "    test_loader_fullwalk = DataLoader(test_loader_fullwalk_examples)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataset_number = 0\n",
    "    for inputs, labels in test_loader_fullwalk:\n",
    "        dataset_number += 1\n",
    "        # Move inputs and labels to the configured device\n",
    "        inputs, labels = inputs.to(configuration.device), labels.to(\n",
    "            configuration.device\n",
    "        )\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Detach outputs from the computation graph and move to CPU for plotting\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        print(f\"Dataset {dataset_number}\")\n",
    "        print(f\"Predicted Stride Width: {scaler_target.inverse_transform(outputs[0][0].reshape(-1, 1))}\")\n",
    "        print(f\"Actual Stride Width: {scaler_target.inverse_transform(labels[0][0].reshape(-1, 1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_statistics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# optional: define model path manually\n",
    "model_filename = \"checkpoints/model_spatial_stridelength_bs1_lr1e-05_epochs30_freezing.pt\"\n",
    "# model_filename = \"checkpoints/model_spatial_stridewidth_bs1_lr0.001_epochs15_freezing.pt\"\n",
    "\n",
    "# Load the model state from the specified checkpoint and set it to evaluation mode\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "model.eval()\n",
    "\n",
    "# Initialize data lists to store true labels and predicted outputs\n",
    "data = [[], [], [], [], []]\n",
    "\n",
    "gt_pd_storage = {\"stridelength\": {}}\n",
    "\n",
    "# Ensure no gradients are computed during evaluation\n",
    "dataset_number = -1\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_fullwalk:\n",
    "        dataset_number += 1\n",
    "        # Move inputs and labels to the configured device\n",
    "        inputs, labels = inputs.to(configuration.device), labels.to(\n",
    "            configuration.device\n",
    "        )\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Detach outputs from the computation graph and move to CPU for plotting\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        act_walk_id = walk_ids_test[dataset_number]\n",
    "\n",
    "        # fill in for statistics\n",
    "        if ids_test_spatial[dataset_number] not in gt_pd_storage[\"stridelength\"]:\n",
    "            gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]] = {\n",
    "                \"gt\": {\n",
    "                    \"slow\": [],\n",
    "                    \"regular\": [],\n",
    "                    \"fast\": [],\n",
    "                    \"slow_walks\": {},\n",
    "                    \"regular_walks\": {},\n",
    "                    \"fast_walks\": {},\n",
    "                },\n",
    "                \"pd\": {\n",
    "                    \"slow\": [],\n",
    "                    \"regular\": [],\n",
    "                    \"fast\": [],\n",
    "                    \"slow_walks\": {},\n",
    "                    \"regular_walks\": {},\n",
    "                    \"fast_walks\": {},\n",
    "                },\n",
    "            }\n",
    "\n",
    "        gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"gt\"][\n",
    "            walk_speed_test[dataset_number]\n",
    "        ].append(\n",
    "            float(\n",
    "                scaler_target.inverse_transform(\n",
    "                    np.array(np.squeeze(labels)).reshape(-1, 1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"pd\"][\n",
    "            walk_speed_test[dataset_number]\n",
    "        ].append(\n",
    "            float(\n",
    "                scaler_target.inverse_transform(\n",
    "                    np.array(np.squeeze(outputs)).reshape(-1, 1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if act_walk_id not in gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"pd\"][walk_speed_test[dataset_number]+\"_walks\"]:\n",
    "            gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"pd\"][walk_speed_test[dataset_number]+\"_walks\"][act_walk_id] = []\n",
    "            gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"gt\"][walk_speed_test[dataset_number]+\"_walks\"][act_walk_id] = []\n",
    "        \n",
    "        gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"pd\"][walk_speed_test[dataset_number]+\"_walks\"][act_walk_id].append(\n",
    "            float(\n",
    "                scaler_target.inverse_transform(\n",
    "                    np.array(np.squeeze(outputs)).reshape(-1, 1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        gt_pd_storage[\"stridelength\"][ids_test_spatial[dataset_number]][\"gt\"][walk_speed_test[dataset_number]+\"_walks\"][act_walk_id].append(\n",
    "            float(\n",
    "                scaler_target.inverse_transform(\n",
    "                    np.array(np.squeeze(labels)).reshape(-1, 1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "statistics = {\n",
    "    \"stridelength\": {\n",
    "        \"mean\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"cv\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"asymmetry\": {\n",
    "            \"gt\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "            \"pd\": {\"slow\": [], \"regular\": [], \"fast\": []},\n",
    "        },\n",
    "        \"rmserel\": {\"slow\": {}, \"regular\": {}, \"fast\": {}},\n",
    "    }\n",
    "}\n",
    "\n",
    "for parameter in gt_pd_storage:\n",
    "    for proband in gt_pd_storage[parameter]:\n",
    "        for sensor in gt_pd_storage[parameter][proband]:\n",
    "            for speed in [\"slow\", \"regular\", \"fast\"]:\n",
    "                values = gt_pd_storage[parameter][proband][sensor][speed]\n",
    "                statistics[parameter][\"mean\"][sensor][speed].append(np.mean(values))\n",
    "                statistics[parameter][\"cv\"][sensor][speed].append(\n",
    "                    (np.std(values) / np.mean(values)) * 100\n",
    "                )\n",
    "                \n",
    "                # Calculate RMSE rel.\n",
    "                if sensor == \"gt\":\n",
    "                    for values_gt_walk, values_pd_walk in zip(\n",
    "                        gt_pd_storage[parameter][proband][\"gt\"][speed+\"_walks\"].values(),\n",
    "                        gt_pd_storage[parameter][proband][\"pd\"][speed+\"_walks\"].values(),\n",
    "                    ):\n",
    "                        values_gt_walk = np.array(values_gt_walk)\n",
    "                        values_pd_walk = np.array(values_pd_walk)\n",
    "                        rmse = np.mean(np.sqrt(np.mean((values_gt_walk - values_pd_walk) ** 2)))\n",
    "                        relative_rmse = (rmse / np.mean(values_gt_walk)) * 100\n",
    "                        \n",
    "                        if proband not in statistics[parameter][\"rmserel\"][speed]:\n",
    "                            statistics[parameter][\"rmserel\"][speed][proband] = []\n",
    "                        \n",
    "                        statistics[parameter][\"rmserel\"][speed][proband].append(relative_rmse)\n",
    "\n",
    "\n",
    "                meanValue0 = np.array(values[1::2])\n",
    "                meanValue1 = np.array(values[0::2])\n",
    "\n",
    "                min_length = min(len(meanValue0), len(meanValue1))\n",
    "\n",
    "                meanValue0 = np.nanmean(meanValue0[:min_length])\n",
    "                meanValue1 = np.nanmean(meanValue1[:min_length])\n",
    "                \n",
    "                if meanValue0 > meanValue1:\n",
    "                    asymmetrie = 100 * (1 - abs(meanValue1 / meanValue0))\n",
    "                else:\n",
    "                    asymmetrie = 100 * (1 - abs(meanValue0 / meanValue1))\n",
    "                    \n",
    "                statistics[parameter][\"asymmetry\"][sensor][speed].append(asymmetrie)\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "for parameter in statistics:\n",
    "    \n",
    "    rmserel_values = {'slow': [], 'regular': [], 'fast': []}\n",
    "    \n",
    "    for speed in statistics[parameter][\"rmserel\"]:\n",
    "        rmserel_values_tmp = []\n",
    "        for proband in statistics[parameter][\"rmserel\"][speed]:\n",
    "            rmserel_values_tmp.append(np.mean(statistics[parameter][\"rmserel\"][speed][proband]))\n",
    "            \n",
    "        rmserel_values[speed] = rmserel_values_tmp\n",
    "        \n",
    "        print(f\"RMSE relative:: Parameter: {parameter}; Speed: {speed}; Probands: {len(rmserel_values_tmp)} ; Mean: {np.mean(rmserel_values_tmp):.4f}; Variance: {np.var(rmserel_values_tmp):.4f}; Std: {np.std(rmserel_values_tmp):.4f}\")\n",
    "    \n",
    "    for speed, data in zip(rmserel_values, rmserel_values.values()):\n",
    "        shapiro_test = stats.shapiro(data)\n",
    "        print(f'Shapiro-Wilk Test {speed}: Statistic={shapiro_test.statistic:.4f}, p-value={shapiro_test.pvalue:.4f}')\n",
    "    \n",
    "    # Perform one-way ANOVA\n",
    "    f_val, p_val = scipy.stats.f_oneway(rmserel_values[\"slow\"], rmserel_values[\"regular\"], rmserel_values[\"fast\"])\n",
    "\n",
    "    print(f'Parameter: {parameter} ANOVA result: F-value = {f_val:.4f}, P-value = {p_val:.4f}')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(rmserel_values.keys(), [np.mean(values) for values in rmserel_values.values()], yerr=[np.std(values) for values in rmserel_values.values()])\n",
    "    plt.xlabel('Speed')\n",
    "    plt.ylabel('RMSE Relative')\n",
    "    plt.ylim(0, 60)\n",
    "    plt.title('RMSE Relative for Different Speeds')\n",
    "    # Save the plot as svg in the rmse_figures folder\n",
    "    plt.savefig(f'rmse_figures/rmse_plot_{parameter}.svg', format=\"svg\")\n",
    "    \n",
    "    plt.show()\n",
    "print(\"here\")\n",
    "\n",
    "def standard_output(metric, parameter):\n",
    "\n",
    "    overall_gt = np.array(\n",
    "        statistics[metric][parameter][\"gt\"][\"fast\"]\n",
    "        + statistics[metric][parameter][\"gt\"][\"slow\"]\n",
    "        + statistics[metric][parameter][\"gt\"][\"regular\"]\n",
    "    )\n",
    "    overall_pd = np.array(\n",
    "        statistics[metric][parameter][\"pd\"][\"fast\"]\n",
    "        + statistics[metric][parameter][\"pd\"][\"slow\"]\n",
    "        + statistics[metric][parameter][\"pd\"][\"regular\"]\n",
    "    )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(overall_gt, overall_pd)\n",
    "    #plt.show()\n",
    "\n",
    "    print(\"============================================\")\n",
    "    print(\"Correlation & Statistics\")\n",
    "    print(\"============================================\")\n",
    "    print(\"SLOW ============================================\")\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"slow\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"slow\"]),\n",
    "        )\n",
    "    )\n",
    "    print(\"REGULAR ============================================\")\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"regular\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"regular\"]),\n",
    "        )\n",
    "    )\n",
    "    print(\"FAST ============================================\")\n",
    "    print(\n",
    "        custom_statistics.uniform_statistics(\n",
    "            np.array(statistics[metric][parameter][\"gt\"][\"fast\"]),\n",
    "            np.array(statistics[metric][parameter][\"pd\"][\"fast\"]),\n",
    "        )\n",
    "    )\n",
    "    print(\"OVERALL ============================================\")\n",
    "    print(custom_statistics.uniform_statistics(overall_gt, overall_pd))\n",
    "\n",
    "\n",
    "standard_output(\"stridelength\", \"mean\")\n",
    "standard_output(\"stridelength\", \"cv\")\n",
    "print(\"asymmetrie ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "standard_output(\"stridelength\", \"asymmetry\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequence-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
